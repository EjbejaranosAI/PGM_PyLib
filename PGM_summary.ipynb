{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PGM PyLib: A Toolkit for Probabilistic Graphical Models in Python\n",
    "### Authors: Jonathan Serrano-Perez - L. Enrique Sucar\n",
    "\n",
    " From: Instituto Nacional de Astrofísica, Óptica y Electrónica, Puebla, Mexico\n",
    "\n",
    "PGM PyLib is a toolkit that contains a wide range of Probabilistic Graphical Models algorithms implemented in Python, and serves as a companion of the book Probabilistic Graphical Models: Principles and Applications. Currently, the algorithms implemented include: Bayesian classifiers, hidden Markov models, Markov random fields, and Bayesian networks; as well as some general functions. The toolkit is open source, can be downloaded from: https://github.com/jona2510/PGM_PyLib .\n",
    "\n",
    "\n",
    "## Presented by Edison Bejarano Universitat Politècnica de Catalunya, Spain - 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXAMPLE OF A BAN CLASSIFIER IN PYTHON\n",
    "An example of how to use the BAN classifier is presented. \n",
    "1. First of all, it is required to import the package which contains the classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a BAN classifier in Python\n",
    "import numpy as np\n",
    "import PGM_PyLib.augmented as abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case we are considering a problem with 4 classes and 5 attributes. \n",
    "\n",
    "np.random.seed(0)   # it is not necessary\n",
    "# Four classes\n",
    "# 5 attributes\n",
    "\n",
    "# 100 instances for training\n",
    "data_train = np.random.randint(0,5,size=(100,5))\n",
    "cl_train = np.random.randint(0,4,size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the data is ready, the next step is to instantiate the classifier with its parameters\n",
    "# 50 instances for testing\n",
    "\n",
    "data_test = np.random.randint(0,5,size=(50,5))\n",
    "cl_test = np.random.randint(0,4,size=50) \n",
    "\n",
    "\n",
    "# in this case, the structure is generated automatically, the smooth used for the estimations of \n",
    "# probabilities is 0.1 and the prior probabilities will be used in the prediction phase.\n",
    "\n",
    "# create the classifiers \n",
    "c = abc.augmentedBC(algStructure=\"auto\", smooth=0.1, usePrior=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24\n",
      "0.24\n"
     ]
    }
   ],
   "source": [
    "#   Then, the classifier is trained with training data. \n",
    "# train the classifier\n",
    "c.fit(data_train, cl_train)\n",
    "\n",
    "#  Once the classifier is trained, it is used to predict the class of new instances.\n",
    "# \n",
    "#  # predict \n",
    "p = c.predict(data_test)\n",
    "# evaluation\n",
    "print(c.exactMatch(cl_test, p))\n",
    "\n",
    "#  Finally, an evaluation measure such as exact-match/accuracy \n",
    "# can be used to evaluated the performance of the classifier .\n",
    "# ignore the Prior probabilities\n",
    "c.usePrior = False\n",
    "p = c.predict(data_test)        # predict\n",
    "print(c.exactMatch(cl_test, p)) # evaluation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import PGM_PyLib.augmented as abc\n",
    "# 5 attributes, 3 classes\n",
    "# simulation of 100 instances for training\n",
    "data_train = np.random.randint(0,5,size=(100,5))\n",
    "cl_train = np.random.randint(0,3,size=100)\n",
    "# simulation of 50 instances for testing\n",
    "data_test = np.random.randint(0,5,size=(50,5))\n",
    "cl_test = np.random.randint(0,3,size=50)\n",
    "# create the classifiers\n",
    "c = abc.augmentedBC(algStructure=\"auto\", smooth=0.1, usePrior=True)\n",
    "c.fit(data_train, cl_train)     # train the classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
